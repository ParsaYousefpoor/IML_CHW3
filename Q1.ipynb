{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1b46fe41",
      "metadata": {
        "id": "1b46fe41"
      },
      "source": [
        "<h1 align=\"center\">Introduction to Machine Learning - Course Code: 25737</h1>\n",
        "<h4 align=\"center\">Instructor: Dr. Amiri</h4>\n",
        "<h4 align=\"center\">Sharif University of Technology, Spring 2024</h4>\n",
        "<h4 align=\"center\">Computer Assignment 3</h4>\n",
        "<h4 align=\"center\">\n",
        "\n",
        "Question 1\n",
        "\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24a0fc13",
      "metadata": {
        "id": "24a0fc13"
      },
      "source": [
        "# Personal Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44babb65",
      "metadata": {
        "id": "44babb65"
      },
      "outputs": [],
      "source": [
        "# Set your student number\n",
        "student_number = 400104686\n",
        "Name = 'Parsa'\n",
        "Last_Name = 'Yousefpoor'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca4a337a",
      "metadata": {
        "id": "ca4a337a"
      },
      "source": [
        "# Rules\n",
        "- You are not allowed to add or remove cells. You **must use the provided space to write your code**. If you don't follow this rule, **your Practical Assignment won't be graded**.  \n",
        "\n",
        "- Collaboration and using the internet is allowed, but your code **must be written by yourself**. **Copying code** from each other or from available resources will result in a **zero score for the assignment**.\n",
        "\n",
        "- You are not allowed to use `torch.nn`, `torch.optim` and any activation function and loss function implemented in torch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12b76789",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12b76789",
        "outputId": "875180b9-a2ae-4029-9126-4f1d5ffa9edb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.3.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->torchvision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install torchvision\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "886188c7",
      "metadata": {
        "id": "886188c7"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a0adcc",
      "metadata": {
        "id": "55a0adcc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18510868",
      "metadata": {
        "id": "18510868"
      },
      "source": [
        "## Datasets and Dataloaders\n",
        "\n",
        "Here, we download and load the train and test `FashionMNIST` dataset with the desired transforms. Then, we define the dataloaders for `train` and `test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc8759e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc8759e2",
        "outputId": "c5b1a9e7-9fc0-4920-9827-44037a796e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 9962249.37it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 201128.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:02<00:00, 1543799.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 14718661.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_set = FashionMNIST(root='.', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_set = FashionMNIST(root='.', train=False, download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df47fcb",
      "metadata": {
        "id": "5df47fcb"
      },
      "source": [
        "\n",
        "Here you have to calculate the number of classes amd input dimention of the first layer (how many pixels does each image have?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f6763e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f6763e6",
        "outputId": "a8a46ad7-9506-4162-97dc-d335d2ab0bee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 10\n",
            "Input dimension of the first layer: 784\n"
          ]
        }
      ],
      "source": [
        "## FILL HERE\n",
        "# Calculate the number of classes\n",
        "num_classes = len(train_set.classes)\n",
        "\n",
        "# Calculate the input dimension of the first layer\n",
        "# Get a sample image from the training set\n",
        "sample_image, _ = train_set[0]\n",
        "\n",
        "# Flatten the image to a 1D tensor\n",
        "flattened_image = sample_image.view(-1)\n",
        "\n",
        "# Get the number of elements in the flattened image\n",
        "input_dim = flattened_image.shape[0]\n",
        "\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Input dimension of the first layer: {input_dim}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c695ff60",
      "metadata": {
        "id": "c695ff60"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, 64, shuffle=True)\n",
        "test_loader = DataLoader(test_set, 64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9dac6c2",
      "metadata": {
        "id": "f9dac6c2"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "Visualize 1 random image from each class by using `plt.subplots`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3d6b0c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "e3d6b0c1",
        "outputId": "79a9feb4-0bcc-4fa0-ca73-24eb93bf6083"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initialize a dictionary to store one image per class\n",
        "class_images: Dict[int, torch.Tensor] = {}\n",
        "\n",
        "# Iterate over the training set to get one image per class\n",
        "for image, label in train_set:\n",
        "    if label not in class_images:\n",
        "        class_images[label] = image\n",
        "    if len(class_images) == num_classes:\n",
        "        break\n",
        "\n",
        "# Create a grid of subplots\n",
        "fig, axes = plt.subplots(1, num_classes, figsize=(15, 15))\n",
        "\n",
        "# Plot one image per class\n",
        "for i, (label, image) in enumerate(class_images.items()):\n",
        "    ax = axes[i]\n",
        "    ax.imshow(image.squeeze(), cmap='gray')\n",
        "    ax.set_title(f'Class: {label}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a94c5aba",
      "metadata": {
        "id": "a94c5aba"
      },
      "source": [
        "## Initializing model's parameters\n",
        "\n",
        "In this part, we create the model and initialize its parameters and store the values of these parameters in the variable `parameters` which is a dictionary including the weigths and biases of each layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d40952",
      "metadata": {
        "id": "e6d40952"
      },
      "outputs": [],
      "source": [
        "def add_linear_layer(parameters: dict, shape, device, i=None):\n",
        "    \"\"\"\n",
        "    This function adds parameters of a linear unit of shape `shape` to the `parameters` dictionary.\n",
        "    \"\"\"\n",
        "    n_in, n_out = shape\n",
        "    with torch.no_grad():\n",
        "        w = torch.zeros(*shape, device=device)\n",
        "        # kaiming initialization for ReLU activations:\n",
        "        bound = 1 / np.sqrt(n_in).item()\n",
        "        w.uniform_(-bound, bound)\n",
        "        b = torch.zeros(n_out, device=device)  # no need to (1, n_out). it will broadcast itself.\n",
        "    w.requires_grad = True\n",
        "    b.requires_grad = True\n",
        "    # `i` is used to give numbers to parameter names\n",
        "    parameters.update({f'w{i}': w, f'b{i}': b})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce914706",
      "metadata": {
        "id": "ce914706"
      },
      "source": [
        "Now we define our neural network with the given layers and add the weights and biases to the dictionary `parameters`. **You are allowed to modify the values of the layers**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f3867d7",
      "metadata": {
        "id": "8f3867d7",
        "outputId": "94be0ab8-a5c5-404b-ca26-31959ee79c42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['w0', 'b0', 'w1', 'b1', 'w2', 'b2', 'w3', 'b3', 'w4', 'b4'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# input_dim : input dimention of the first layer, which you have calculated before.\n",
        "layers = [\n",
        "    (input_dim, 512),\n",
        "    (512, 256),\n",
        "    (256, 128),\n",
        "    (128, 64),\n",
        "    (64, num_classes)\n",
        "]\n",
        "num_layers = len(layers)\n",
        "parameters = {}\n",
        "\n",
        "# setting the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# adding the parameters to the dictionary\n",
        "for i, shape in enumerate(layers):\n",
        "    add_linear_layer(parameters, shape, device, i)\n",
        "\n",
        "parameters.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bfd2c8e",
      "metadata": {
        "id": "8bfd2c8e"
      },
      "source": [
        "## Defining the required functions\n",
        "\n",
        "In this section, we should define the required functions. For each of these functions, the inputs and the desired outputs are given and you should write all or part of the function. **You are not allowed to use the activation functions and the loss functions implemented in torch**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b413d8",
      "metadata": {
        "id": "f3b413d8"
      },
      "source": [
        "Computing affine and relu outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bebeeb0e",
      "metadata": {
        "id": "bebeeb0e"
      },
      "outputs": [],
      "source": [
        "def affine_forward(x, w, b):\n",
        "    ## FILL HERE\n",
        "    if x.shape[1] != w.shape[0]:\n",
        "      x = torch.transpose(w, 0, 1)\n",
        "    return torch.matmul(x, w) + b\n",
        "\n",
        "def relu(x):\n",
        "    ## FILL HERE\n",
        "    return torch.max(x, torch.zeros_like(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d9baa5e",
      "metadata": {
        "id": "5d9baa5e"
      },
      "source": [
        "Function `model` returns output of the whole model for the input `x` using the parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2562962",
      "metadata": {
        "id": "d2562962"
      },
      "outputs": [],
      "source": [
        "def model(x: torch.Tensor, parameters, num_layers=num_layers):\n",
        "    # number of batches\n",
        "    B = x.shape[0]\n",
        "    x = x.view(B, -1)\n",
        "\n",
        "    ## FILL HERE\n",
        "    for i in range(num_layers):\n",
        "        w = parameters[f'w{i}']\n",
        "        b = parameters[f'b{i}']\n",
        "        x = affine_forward(x, w, b)\n",
        "        x = relu(x)\n",
        "\n",
        "    output = affine_forward(x, parameters[f'w{num_layers - 1}'], parameters[f'b{num_layers - 1}'])\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d17a9b4c",
      "metadata": {
        "id": "d17a9b4c"
      },
      "source": [
        "Implementing cross entropy loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6959621c",
      "metadata": {
        "id": "6959621c"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_loss(scores, y):\n",
        "    n = len(y)\n",
        "    ## FILL HERE\n",
        "    log_probs = torch.nn.functional.log_softmax(scores, dim=1)\n",
        "    print(y.shape)\n",
        "    print(log_probs.shape)\n",
        "    loss = -log_probs.gather(1, y.view(-1, 1)).sum() / n\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15a589af",
      "metadata": {
        "id": "15a589af"
      },
      "source": [
        "Implementing a function for optimizing paramters and a function to zeroing out their gradients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3121c147",
      "metadata": {
        "id": "3121c147"
      },
      "outputs": [],
      "source": [
        "def sgd_optimizer(parameters: Dict[str, torch.Tensor], learning_rate=0.001):\n",
        "    '''This function gets the parameters and a learning rate. Then updates the parameters using their\n",
        "    gradient. Finally, you should zero the gradients of the parameters after updating\n",
        "    the parameter value.'''\n",
        "    ## FILL HERE\n",
        "    for param in parameters.values():\n",
        "        param.grad.data *= -learning_rate  # Gradient descent update\n",
        "        param.data += param.grad.data  # Update parameters\n",
        "        param.grad.data.zero_()  # Zero out gradients for next iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17b4cf8",
      "metadata": {
        "id": "e17b4cf8"
      },
      "source": [
        "Training functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76c0f03b",
      "metadata": {
        "id": "76c0f03b"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_pred: np.ndarray, y_true: np.ndarray):\n",
        "    ## FILL HERE\n",
        "    acc = np.mean(y_pred == y_true)\n",
        "    return acc\n",
        "\n",
        "def train(train_loader, learning_rate=0.001, epoch=None):\n",
        "    '''This function implements the training loop for a single epoch. For each batch you should do the following:\n",
        "        1- Calculate the output of the model to the given input batch\n",
        "        2- Calculate the loss based on the model output\n",
        "        3- Update the gradients using backward method\n",
        "        4- Optimize the model parameters using the sgd_optimizer function defined previously\n",
        "        5- Print the train loss (Show the epoch and batch as well)\n",
        "        '''\n",
        "    train_loss = 0\n",
        "    N_train = len(train_loader.dataset)\n",
        "\n",
        "    # Creating empty lists Y and Y_pred to store the labels and predictions of each batch\n",
        "    # for calculateing the accuracy later\n",
        "    Y = []\n",
        "    Y_pred = []\n",
        "\n",
        "\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        p = model(x, parameters)\n",
        "\n",
        "        ## FILL HERE\n",
        "        loss = cross_entropy_loss(p, y)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        sgd_optimizer(parameters, learning_rate)\n",
        "\n",
        "        y_pred = p.argmax(dim=-1)\n",
        "        Y.append(y.cpu().numpy())\n",
        "        Y_pred.append(y_pred.cpu().numpy())\n",
        "\n",
        "    Y = np.concatenate(Y)\n",
        "    Y_pred = np.concatenate(Y_pred)\n",
        "    acc = accuracy(Y_pred, Y)\n",
        "    print(f'Accuracy of train set: {acc}')\n",
        "    return train_loss, acc\n",
        "\n",
        "\n",
        "def validate(loader, epoch=None, set_name=None):\n",
        "    '''This function validates the model on the test dataloader. The function goes through each batch and does\n",
        "    the following on each batch:\n",
        "        1- Calculate the model output\n",
        "        2- Calculate the loss using the model output\n",
        "        3- Print the loss for each batch and epoch\n",
        "\n",
        "    Finally the function calculates the model accuracy.'''\n",
        "    total_loss = 0\n",
        "    N = len(loader.dataset)\n",
        "\n",
        "    # Creating empty lists Y and Y_pred to store the labels and predictions of each batch\n",
        "    # for calculateing the accuracy later\n",
        "    Y = []\n",
        "    Y_pred = []\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        p = model(x, parameters)\n",
        "\n",
        "        ## FILL HERE\n",
        "        loss = cross_entropy_loss(p, y)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        y_pred = p.argmax(dim=-1)\n",
        "        Y.append(y.cpu().numpy())\n",
        "        Y_pred.append(y_pred.cpu().numpy())\n",
        "    Y = np.concatenate(Y)\n",
        "    Y_pred = np.concatenate(Y_pred)\n",
        "    total_loss /= N\n",
        "    acc = accuracy(Y_pred, Y)\n",
        "    print(f'Accuracy of {set_name} set: {acc}')\n",
        "\n",
        "    return total_loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ebb4b6",
      "metadata": {
        "id": "87ebb4b6"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d4eb0b",
      "metadata": {
        "id": "28d4eb0b"
      },
      "outputs": [],
      "source": [
        "def train_model(dataloaders, num_epochs, learning_rate=0.001, model_name='pytorch_model'):\n",
        "    '''This function trains the model for the number of epochs given and stores, calculates and prints the train\n",
        "    and test losses and accuracies. Finally, it plots the accuracy and loss history for training and test sets'''\n",
        "    train_loader, test_loader = dataloaders\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        ## FILL HERE\n",
        "        ## You should calculate the train and test loss and accuracies for each epoch and add them to\n",
        "        ## the lists `train_losses`, `test_losses`, `train_accuracies` and `test_accuracies`\n",
        "        train_loss, train_acc = train(train_loader, learning_rate, epoch)\n",
        "        test_loss, test_acc = validate(test_loader, epoch, set_name='Test')\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(test_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "    ## plot the loss history of training and test sets\n",
        "    ## FILL HERE\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(test_losses, label='Test Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss History')\n",
        "    plt.show()\n",
        "\n",
        "    ## plot the accuracy history of training and test sets\n",
        "    ## FILL HERE\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_accuracies, label='Train Accuracy')\n",
        "    plt.plot(test_accuracies, label='Test Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy History')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ec4bdd2",
      "metadata": {
        "id": "2ec4bdd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "429861f0-62e0-430b-e275-9addc94ada04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 10])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n",
            "torch.Size([10, 10])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Size does not match at dimension 0 expected index [64, 1] to be smaller than self [10, 10] apart from dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-abc380480f01>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-3efa6b2b6441>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(dataloaders, num_epochs, learning_rate, model_name)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m## You should calculate the train and test loss and accuracies for each epoch and add them to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m## the lists `train_losses`, `test_losses`, `train_accuracies` and `test_accuracies`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-a420275eb9b5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, learning_rate, epoch)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-4b86c1e6c9e1>\u001b[0m in \u001b[0;36mcross_entropy_loss\u001b[0;34m(scores, y)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Size does not match at dimension 0 expected index [64, 1] to be smaller than self [10, 10] apart from dimension 1"
          ]
        }
      ],
      "source": [
        "train_model([train_loader, test_loader], num_epochs=25, learning_rate=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceb5783f",
      "metadata": {
        "id": "ceb5783f"
      },
      "outputs": [],
      "source": [
        "print(f'Final test accuracy: {test_accuracies[-1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5e128ed",
      "metadata": {
        "id": "a5e128ed"
      },
      "source": [
        "## Visualization of the labels and predictions\n",
        "\n",
        "In this section, you should visual one image from each class and show both the actual label and the predicted label for that image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c0b79fd",
      "metadata": {
        "id": "6c0b79fd"
      },
      "outputs": [],
      "source": [
        "## FILL HERE"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}